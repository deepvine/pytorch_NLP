{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## char-CNN emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import vocab\n",
    "from torchtext import data\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator\n",
    "from torchtext.vocab import GloVe\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pickle\n",
    "import dill\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    return x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>xxxPEACHESxxx</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>mcsleazy</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment         author  \\\n",
       "0  1956967341       empty     xoshayzers   \n",
       "1  1956967666     sadness      wannamama   \n",
       "2  1956967696     sadness      coolfunky   \n",
       "3  1956967789  enthusiasm    czareaquino   \n",
       "4  1956968416     neutral      xkilljoyx   \n",
       "5  1956968477       worry  xxxPEACHESxxx   \n",
       "6  1956968487     sadness       ShansBee   \n",
       "7  1956968636       worry       mcsleazy   \n",
       "8  1956969035     sadness    nic0lepaula   \n",
       "9  1956969172     sadness     Ingenue_Em   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  \n",
       "5  Re-pinging @ghostridah14: why didn't you go to...  \n",
       "6  I should be sleep, but im not! thinking about ...  \n",
       "7               Hmmm. http://www.djhero.com/ is down  \n",
       "8            @charviray Charlene my love. I miss you  \n",
       "9         @kelcouch I'm sorry  at least it's Friday?  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/text_emotion.csv\"\n",
    "allFiles = glob.glob(path)\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, sep=',')\n",
    "    list_.append(df)\n",
    "dataset = pd.concat(list_, axis = 0, ignore_index = True)\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = \"<blank>\"\n",
    "max_vocab = 8000\n",
    "fix_length=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_NESTING = Field(sequential=True, tokenize=lambda x: list(x), pad_token=BLANK_WORD, lower=True, batch_first=True, fix_length=fix_length)\n",
    "CHAR = data.NestedField(CHAR_NESTING)\n",
    "WORD_NESTING = Field(sequential=True, tokenize=lambda x: x.split(), pad_token=BLANK_WORD, lower=True, batch_first=True, fix_length=fix_length)\n",
    "WORD = data.NestedField(WORD_NESTING)\n",
    "LABEL = Field(sequential=False, unk_token=None, tokenize=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHAR = Field(sequential=True, tokenize=lambda x: list(x), pad_token=BLANK_WORD, lower=True, batch_first=True, fix_length=fix_length)\n",
    "#LABEL = Field(sequential=False, unk_token=None, tokenize=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv\n",
    "train_data = TabularDataset(path='../data/text_emotion.csv', \n",
    "                            format='csv', \n",
    "                            skip_header=True,\n",
    "                            fields=[(\"tweet_id\", None),(\"sentiment\", LABEL),(\"author\", None),((\"word\", \"char\"),(WORD, CHAR))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove = vocab.Vectors('../data/glove.6B.300d.txt')\n",
    "#tqdm_notebook().pandas() \n",
    "#https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.build_vocab(train_data, max_size=max_vocab)\n",
    "WORD.build_vocab(train_data.word)\n",
    "CHAR.build_vocab(train_data.char, min_freq=3)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "            {'<unk>': 0,\n",
       "             '<blank>': 1,\n",
       "             'e': 2,\n",
       "             't': 3,\n",
       "             'o': 4,\n",
       "             'a': 5,\n",
       "             'i': 6,\n",
       "             'n': 7,\n",
       "             's': 8,\n",
       "             'r': 9,\n",
       "             'h': 10,\n",
       "             'l': 11,\n",
       "             'd': 12,\n",
       "             'm': 13,\n",
       "             'u': 14,\n",
       "             'y': 15,\n",
       "             'g': 16,\n",
       "             'w': 17,\n",
       "             'c': 18,\n",
       "             '.': 19,\n",
       "             'p': 20,\n",
       "             'f': 21,\n",
       "             'b': 22,\n",
       "             'k': 23,\n",
       "             'v': 24,\n",
       "             '!': 25,\n",
       "             '@': 26,\n",
       "             \"'\": 27,\n",
       "             ',': 28,\n",
       "             'j': 29,\n",
       "             '?': 30,\n",
       "             '/': 31,\n",
       "             'x': 32,\n",
       "             'z': 33,\n",
       "             ';': 34,\n",
       "             '-': 35,\n",
       "             '&': 36,\n",
       "             ':': 37,\n",
       "             'q': 38,\n",
       "             '1': 39,\n",
       "             '2': 40,\n",
       "             '0': 41,\n",
       "             '3': 42,\n",
       "             '_': 43,\n",
       "             '4': 44,\n",
       "             '5': 45,\n",
       "             '6': 46,\n",
       "             '8': 47,\n",
       "             '7': 48,\n",
       "             ')': 49,\n",
       "             '9': 50,\n",
       "             '(': 51,\n",
       "             '*': 52,\n",
       "             '#': 53,\n",
       "             '½': 54,\n",
       "             '¿': 55,\n",
       "             'ï': 56,\n",
       "             '=': 57,\n",
       "             '~': 58,\n",
       "             '$': 59,\n",
       "             '+': 60,\n",
       "             ']': 61,\n",
       "             '^': 62,\n",
       "             '%': 63,\n",
       "             '[': 64,\n",
       "             '`': 65,\n",
       "             '|': 66,\n",
       "             '\\\\': 67,\n",
       "             '{': 68,\n",
       "             '}': 69,\n",
       "             'â': 70})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@tiffanylue'], ['i'], ['know'], ['i'], ['was'], ['listenin'], ['to'], ['bad'], ['habit'], ['earlier'], ['and'], ['i'], ['started'], ['freakin'], ['at'], ['his'], ['part'], ['=[']]\n",
      "[['@', 't', 'i', 'f', 'f', 'a', 'n', 'y', 'l', 'u', 'e'], ['i'], ['k', 'n', 'o', 'w'], ['i'], ['w', 'a', 's'], ['l', 'i', 's', 't', 'e', 'n', 'i', 'n'], ['t', 'o'], ['b', 'a', 'd'], ['h', 'a', 'b', 'i', 't'], ['e', 'a', 'r', 'l', 'i', 'e', 'r'], ['a', 'n', 'd'], ['i'], ['s', 't', 'a', 'r', 't', 'e', 'd'], ['f', 'r', 'e', 'a', 'k', 'i', 'n'], ['a', 't'], ['h', 'i', 's'], ['p', 'a', 'r', 't'], ['=', '[']]\n"
     ]
    }
   ],
   "source": [
    "one_example = train_data.examples[0]\n",
    "print(one_example.word)\n",
    "print(one_example.char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Iterator(train_data, \n",
    "                        batch_size=batch_size, \n",
    "                        repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 24, 30])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    break;\n",
    "#print(batch.word.shape)    \n",
    "#print(batch.word[:,:3,:4])\n",
    "print(batch.char.shape)\n",
    "#print(batch.char[:,:3,:6])\n",
    "print(batch.sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR.vocab.itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/CHAR2.Field\",\"wb\")as f:\n",
    "     dill.dump(CHAR,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/LABEL_CHAR2.Field\",\"wb\")as f2:\n",
    "     dill.dump(LABEL,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(model, method='xavier', exclude='embedding', seed=123):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    for name, w in model.named_parameters():\n",
    "        if not exclude in name:\n",
    "            if 'weight' in name:\n",
    "                if method is 'xavier':\n",
    "                    nn.init.xavier_normal_(w)\n",
    "                elif method is 'kaiming':\n",
    "                    nn.init.kaiming_normal_(w)\n",
    "                else:\n",
    "                    nn.init.normal_(w)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(w, 0.0)\n",
    "            else: \n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model, ignore='embedding'):\n",
    "    total = 0\n",
    "    for name, w in model.named_parameters():\n",
    "        if not ignore or ignore not in name:\n",
    "            total += w.nelement()\n",
    "            print('{} : {}  {} parameters'.format(name, w.shape, w.nelement()))\n",
    "    print('-------'*4)\n",
    "    print('Total {} parameters'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/CHAR2.Field\",\"rb\")as f:\n",
    "     CHAR=dill.load(f)\n",
    "        \n",
    "with open(\"model/LABEL_CHAR2.Field\",\"rb\")as f2:\n",
    "     LABEL=dill.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbatch_size=64\\nepochs=200\\nembidding_dim = 300\\nseq_length = 50\\nvocab_size = len(TEXT.vocab.itos)\\nnum_filters = 128\\nkernel_sizes = [1,2,3,4,56,]\\nhidden_dim = 128 # hidden size of fully conntected layer\\nlabel_size = len(LABEL.vocab)\\nprint_every = 1000\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "batch_size=64\n",
    "epochs=200\n",
    "embidding_dim = 300\n",
    "seq_length = 50\n",
    "vocab_size = len(TEXT.vocab.itos)\n",
    "num_filters = 128\n",
    "kernel_sizes = [1,2,3,4,56,]\n",
    "hidden_dim = 128 # hidden size of fully conntected layer\n",
    "label_size = len(LABEL.vocab)\n",
    "print_every = 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab_size = len(CHAR.vocab.itos)\n",
    "char_embed_dim = 15\n",
    "label_size = len(LABEL.vocab.itos)\n",
    "#word_vocab_size = len(LABEL.vocab.itos)\n",
    "#word_embed_dim = 256\n",
    "\n",
    "kernel_widths = [1, 2, 3, 4, 5, 6]\n",
    "kernel_sizes = [25, 50, 75, 100, 125, 150] #525\n",
    "dropout_prob = 0.5\n",
    "\n",
    "rnn_hidden = 256\n",
    "lstm_num_layers = 2\n",
    "\n",
    "param_init = 0.05\n",
    "learning_rate_decay = 0.5\n",
    "decay_when = 1.0\n",
    "learning_rate = 1.0\n",
    "\n",
    "\n",
    "max_epoch = 200\n",
    "max_steps = 10000\n",
    "max_sent_len = 35\n",
    "max_word_len = 30\n",
    "clip = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Highway, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size, bias=True)\n",
    "        self.fc2 = nn.Linear(input_size, input_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        G = relu(x, Wg)\n",
    "        T = sigmoid(x, Wt)\n",
    "                                   |x, T == 0\n",
    "        y = G * T + x * (1. - T) = |\n",
    "                                   |G, T == 1\n",
    "        \"\"\"\n",
    "        #print(x.shape)\n",
    "        t = F.sigmoid(self.fc1(x))\n",
    "        return torch.mul(t, F.relu(self.fc2(x))) + torch.mul(1-t, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayNetwork(nn.Module):\n",
    "    def __init__(self, input_size,activation='ReLU'):\n",
    "        super(HighwayNetwork, self).__init__()\n",
    "        #transform gate\n",
    "        self.trans_gate = nn.Sequential(\n",
    "            nn.Linear(input_size,input_size),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "        #highway\n",
    "        if activation== 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "            \n",
    "        self.h_layer = nn.Sequential(\n",
    "            nn.Linear(input_size,input_size),\n",
    "            self.activation)\n",
    "        #self.trans_gate[0].weight.data.uniform_(-0.05,0.05)\n",
    "        #self.h_layer[0].weight.data.uniform_(-0.05,0.05)\n",
    "        self.trans_gate[0].bias.data.fill_(-2)\n",
    "        #self.h_layer[0].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        t = self.trans_gate(x)\n",
    "        h = self.h_layer(x)\n",
    "\n",
    "        z = torch.mul(t,h)+torch.mul(1-t,x)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    #num_filters = out-channels\n",
    "    def __init__(self, char_vocab, embed_dim, kernel_sizes, kernel_widths):\n",
    "        super(CharCNN, self).__init__()\n",
    "        \n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.kernel_widths = kernel_widths\n",
    "        \n",
    "        self.kernel = list(zip(kernel_sizes, kernel_widths)) \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, out_channel, \n",
    "                                              kernel_size=(kernel_widths, embed_dim))  # (height, width)\n",
    "                                      for out_channel, kernel_widths in self.kernel])\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pooled = []\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            conved = F.tanh(conv(x).squeeze(3))\n",
    "            #pool  = F.max_pool2d(conved, max_word_len-kernel_widths[i],1)\n",
    "            pool = F.max_pool1d(conved, conved.shape[2]).squeeze(2)\n",
    "            pooled.append(pool)\n",
    "        \n",
    "        cat = torch.cat(pooled, 1)\n",
    "        \n",
    "        return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN_LSTM(nn.Module):\n",
    "    def __init__(self, char_vocab, embed_dim, hidden_dim, label_size,\n",
    "                 kernel_sizes, kernel_widths, lstm_num_layers, dropout_prob):\n",
    "        super(CharCNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.char_vocab = char_vocab\n",
    "        self.embed_dim = embed_dim\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #cnn layer\n",
    "        self.char_embed = nn.Embedding(char_vocab, embed_dim, padding_idx=1)\n",
    "        self.conv = CharCNN(char_vocab, embed_dim, kernel_sizes, kernel_widths)\n",
    "        \n",
    "        # highway lyaer\n",
    "        self.highway_input_dim = sum([x for x in kernel_sizes])\n",
    "        #self.highway1 = Highway(self.highway_input_dim)\n",
    "        #self.highway2 = Highway(self.highway_input_dim)\n",
    "        self.highway1 = HighwayNetwork(self.highway_input_dim)\n",
    "        self.highway2 = HighwayNetwork(self.highway_input_dim)\n",
    "        #self.batch_norm = nn.BatchNorm1d(self.highway_input_dim, affine=False)\n",
    "        \n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(self.highway_input_dim, \n",
    "                            self.hidden_dim, \n",
    "                            lstm_num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout = dropout_prob)\n",
    "        \n",
    "        # output layer\n",
    "        self.drop = nn.Dropout(dropout_prob)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.linear = nn.Linear(self.hidden_dim, label_size)\n",
    "        self.hidden = None\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        this_batch_size = x.size()[0]\n",
    "        this_seq_len = x.size()[1]\n",
    "        #max_word_len = x.size()[2]\n",
    "        max_wlen = max_word_len\n",
    "        \n",
    "        x = x.contiguous().view(-1, x.size()[2])\n",
    "        #x = x.contiguous().view(-1, max_wlen)\n",
    "\n",
    "        emb = self.char_embed(x)\n",
    "        #emb = emb.view(x.shape[0],1,x.shape[1],x.shape[2])\n",
    "        #emb = emb.view(-1, self.char_embed_dim)\n",
    "        emb = emb.unsqueeze(1)\n",
    "\n",
    "        cnn = self.conv(emb)\n",
    "        \n",
    "        #cnn = self.batch_norm(cnn)\n",
    "\n",
    "        h_ = self.highway1(cnn) \n",
    "        h_ = self.highway2(h_)\n",
    "        \n",
    "        #h_ = h_.view(batch_size, -1, self.highway_input_dim)\n",
    "        #h_ = h_.contiguous().view(batch_size, -1, self.highway_input_dim)\n",
    "        h_ = h_.contiguous().view(this_batch_size,this_seq_len, -1)\n",
    "        \n",
    "        #print(\"h_ : \", h_.shape)\n",
    "        #print(\"hidden : \", hidden[0].shape)\n",
    "        #self.hidden = self.init_hidden(this_batch_size)\n",
    "        \n",
    "        output, h = self.lstm(h_, h)\n",
    "        #print(\"out : \", output.shape)\n",
    "        \n",
    "        out = output.contiguous().view(this_batch_size, this_seq_len, -1)\n",
    "        #output = self.drop(output)\n",
    "        \n",
    "\n",
    "        #decoded = output[:,-1]\n",
    "        #print(out.shape)\n",
    "        out = self.linear(out[:, -1])\n",
    "        #print(out.shape)\n",
    "        y = self.softmax(out)\n",
    "        #print(y.shape)\n",
    "        return y, h\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (Variable(weight.new(self.lstm_num_layers, batch_size, self.hidden_dim).zero_()).cuda(),\n",
    "                  Variable(weight.new(self.lstm_num_layers, batch_size, self.hidden_dim).zero_()).cuda())\n",
    "        else:\n",
    "            hidden = (Variable(weight.new(self.lstm_num_layers, batch_size, self.hidden_dim).zero_()),\n",
    "                      Variable(weight.new(self.lstm_num_layers, batch_size, self.hidden_dim).zero_()))\n",
    "        return hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용할 수 있는지 확인\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "#train_on_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        return Variable(x, volatile=volatile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharCNN_LSTM(\n",
       "  (char_embed): Embedding(71, 15, padding_idx=1)\n",
       "  (conv): CharCNN(\n",
       "    (convs): ModuleList(\n",
       "      (0): Conv2d(1, 25, kernel_size=(1, 15), stride=(1, 1))\n",
       "      (1): Conv2d(1, 50, kernel_size=(2, 15), stride=(1, 1))\n",
       "      (2): Conv2d(1, 75, kernel_size=(3, 15), stride=(1, 1))\n",
       "      (3): Conv2d(1, 100, kernel_size=(4, 15), stride=(1, 1))\n",
       "      (4): Conv2d(1, 125, kernel_size=(5, 15), stride=(1, 1))\n",
       "      (5): Conv2d(1, 150, kernel_size=(6, 15), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (highway1): HighwayNetwork(\n",
       "    (trans_gate): Sequential(\n",
       "      (0): Linear(in_features=525, out_features=525, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (h_layer): Sequential(\n",
       "      (0): Linear(in_features=525, out_features=525, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (highway2): HighwayNetwork(\n",
       "    (trans_gate): Sequential(\n",
       "      (0): Linear(in_features=525, out_features=525, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (h_layer): Sequential(\n",
       "      (0): Linear(in_features=525, out_features=525, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(525, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (softmax): LogSoftmax()\n",
       "  (linear): Linear(in_features=256, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CharCNN_LSTM(char_vocab_size, char_embed_dim, rnn_hidden, label_size,\n",
    "                     kernel_sizes, kernel_widths, lstm_num_layers, dropout_prob)\n",
    "init_network(model)\n",
    "if(train_on_gpu):\n",
    "    model.cuda()\n",
    "    \n",
    "#hidden_state = model.init_hidden(batch_size)\n",
    "#model.hidden = model.init_hidden(batch_size)\n",
    "\n",
    "hidden_state = (to_var(torch.zeros(2,batch_size,rnn_hidden)),to_var(torch.zeros(2,batch_size,rnn_hidden)))\n",
    "    \n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_embed.weight : torch.Size([71, 15])  1065 parameters\n",
      "conv.convs.0.weight : torch.Size([25, 1, 1, 15])  375 parameters\n",
      "conv.convs.0.bias : torch.Size([25])  25 parameters\n",
      "conv.convs.1.weight : torch.Size([50, 1, 2, 15])  1500 parameters\n",
      "conv.convs.1.bias : torch.Size([50])  50 parameters\n",
      "conv.convs.2.weight : torch.Size([75, 1, 3, 15])  3375 parameters\n",
      "conv.convs.2.bias : torch.Size([75])  75 parameters\n",
      "conv.convs.3.weight : torch.Size([100, 1, 4, 15])  6000 parameters\n",
      "conv.convs.3.bias : torch.Size([100])  100 parameters\n",
      "conv.convs.4.weight : torch.Size([125, 1, 5, 15])  9375 parameters\n",
      "conv.convs.4.bias : torch.Size([125])  125 parameters\n",
      "conv.convs.5.weight : torch.Size([150, 1, 6, 15])  13500 parameters\n",
      "conv.convs.5.bias : torch.Size([150])  150 parameters\n",
      "highway1.trans_gate.0.weight : torch.Size([525, 525])  275625 parameters\n",
      "highway1.trans_gate.0.bias : torch.Size([525])  525 parameters\n",
      "highway1.h_layer.0.weight : torch.Size([525, 525])  275625 parameters\n",
      "highway1.h_layer.0.bias : torch.Size([525])  525 parameters\n",
      "highway2.trans_gate.0.weight : torch.Size([525, 525])  275625 parameters\n",
      "highway2.trans_gate.0.bias : torch.Size([525])  525 parameters\n",
      "highway2.h_layer.0.weight : torch.Size([525, 525])  275625 parameters\n",
      "highway2.h_layer.0.bias : torch.Size([525])  525 parameters\n",
      "lstm.weight_ih_l0 : torch.Size([1024, 525])  537600 parameters\n",
      "lstm.weight_hh_l0 : torch.Size([1024, 256])  262144 parameters\n",
      "lstm.bias_ih_l0 : torch.Size([1024])  1024 parameters\n",
      "lstm.bias_hh_l0 : torch.Size([1024])  1024 parameters\n",
      "lstm.weight_ih_l1 : torch.Size([1024, 256])  262144 parameters\n",
      "lstm.weight_hh_l1 : torch.Size([1024, 256])  262144 parameters\n",
      "lstm.bias_ih_l1 : torch.Size([1024])  1024 parameters\n",
      "lstm.bias_hh_l1 : torch.Size([1024])  1024 parameters\n",
      "linear.weight : torch.Size([13, 256])  3328 parameters\n",
      "linear.bias : torch.Size([13])  13 parameters\n",
      "----------------------------\n",
      "Total 2471784 parameters\n"
     ]
    }
   ],
   "source": [
    "#criterion = F.cross_entropy\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,momentum=0.8)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.85)\n",
    "print_model(model, ignore=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h): # todo\n",
    "    \"\"\" wraps hidden states in new Variable, to detach them from their history \"\"\"\n",
    "    #print(type(h))\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(Variable(v.data) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-739807011945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#loss = F.cross_entropy(output, targets.view(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#torch.nn.utils.clip_grad_norm(net.parameters(), 5, norm_type=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "print_every = 100\n",
    "\n",
    "best_acc = 0.0\n",
    "counter = 0\n",
    "index = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        counter += 1\n",
    "        \n",
    "        #print(batch.char.shape)\n",
    "        #print(batch.sentiment.shape)\n",
    "        #if len(batch) != batch_size: continue\n",
    "        if(train_on_gpu):\n",
    "            inputs, targets = Variable(batch.char).cuda(), Variable(batch.sentiment).cuda()\n",
    "        else:\n",
    "            inputs, targets = batch.char, batch.sentiment\n",
    "        counter += 1\n",
    "        \n",
    "        #hidden_state = repackage_hidden(model.hidden)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        #output, hidden_state = model(inputs, hidden_state)\n",
    "        output, hidden_state = model(inputs, hidden_state)\n",
    "        #print(\"output: \", output.shape)\n",
    "        #print(\"targets: \", targets.shape)\n",
    "        \n",
    "        #print(\"out : \", output.shape)\n",
    "        #print(hidden_state[0].shape)\n",
    "        \n",
    "        #print(targets.view(-1).shape)\n",
    "        targets = targets.view(batch_size)\n",
    "        loss = criterion(output, targets)\n",
    "        #loss = F.cross_entropy(output, targets.view(-1))\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm(net.parameters(), 5, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename = \"cls_emotion_char_cnn2.pth\"\n",
    "PATH = os.path.join(\"model\", filename)\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TextCNN(TEXT.vocab.vectors, TEXT.vocab.stoi[TEXT.pad_token], num_filters, kernel_sizes, label_size, 0.5)\n",
    "model = TextCNN(TEXT.vocab.vectors, TEXT.vocab.stoi[TEXT.pad_token], vocab_size, embidding_dim, num_filters, kernel_sizes, label_size, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = \"How are YOU convinced that I have always wanted you? What signals did I give off...damn I think I just lost another friend\"\n",
    "#sentence = \"The storm is here and the electricity is gone\"\n",
    "#sentence = \"Damm servers still down  i need to hit 80 before all the koxpers pass me\"\n",
    "#sentence = \"Need to pack for CALI CALI! Cannot waittt! Thinking a glass of wine is in order to celebrate my weekend vaca. Still work 2morrow, tho.\"\n",
    "#sentence = \"I'm worried I can do anything\"\n",
    "##sentence = \"I felt ecstatic when I passed my exam\"\n",
    "#sentence = \"I was overjoyed at the birth of my son.\"\n",
    "sentence = \"During the Christmas holidays I felt wonderfully merry.\"\n",
    "#sentence = \"I’m feeling a little low at the moment.\"\n",
    "#sentence = \"I was so annoyed when I failed my English test.\"\n",
    "#sentence = \"Afraid of your own shadow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[828, 4, 3278, 1925, 2, 872, 0, 0]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [TEXT.vocab.stoi[word.lower()] for word in tokenizer(sentence)]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse = np.asarray(s)\n",
    "feature_tensor = torch.from_numpy(nse)\n",
    "feature_tensor = feature_tensor.unsqueeze(0)\n",
    "batch_size = feature_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "if(train_on_gpu):\n",
    "    feature_tensor = feature_tensor.cuda()\n",
    "    model.cuda()\n",
    "\n",
    "model.eval()\n",
    "print(feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3.4776,   3.9867,  -1.0742,   1.3718,   2.4690,  -5.4473,  -7.9056,\n",
       "        -15.8092, -10.7468,  -4.9786,  -8.9972, -10.3861, -16.7447],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(feature_tensor).squeeze()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3.4776,   3.9867,  -1.0742,   1.3718,   2.4690,  -5.4473,  -7.9056,\n",
       "        -15.8092, -10.7468,  -4.9786,  -8.9972, -10.3861, -16.7447],\n",
       "       grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pred = F.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "val,idx = pred.sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2631e-01, 3.1634e-01, 1.1538e-01, 3.8514e-02, 3.3369e-03, 6.7245e-05,\n",
       "        4.2082e-05, 3.6016e-06, 1.2089e-06, 3.0147e-07, 2.1017e-07, 1.3304e-09,\n",
       "        5.2203e-10], device='cuda:0', grad_fn=<SortBackward>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0,  4,  3,  2,  9,  5,  6, 10, 11,  8,  7, 12], device='cuda:0')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263\n",
      "0.3163\n",
      "0.1154\n",
      "0.0385\n",
      "0.0033\n",
      "0.0001\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "value = []\n",
    "for v in val.tolist():\n",
    "    v = round(v, 4)\n",
    "    value.append(v)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5263, 0.3163, 0.1154, 0.0385]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "9\n",
      "5\n",
      "6\n",
      "10\n",
      "11\n",
      "8\n",
      "7\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "emotion = []\n",
    "for v in idx.tolist():\n",
    "    emotion.append(LABEL.vocab.itos[v])\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worry', 'neutral', 'love', 'sadness']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fc776133d08>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = zip(emotion, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('worry', 0.5263)\n",
      "('neutral', 0.3163)\n",
      "('love', 0.1154)\n",
      "('sadness', 0.0385)\n",
      "('happiness', 0.0033)\n",
      "('empty', 0.0001)\n",
      "('surprise', 0.0)\n",
      "('fun', 0.0)\n",
      "('enthusiasm', 0.0)\n",
      "('boredom', 0.0)\n",
      "('hate', 0.0)\n",
      "('relief', 0.0)\n",
      "('anger', 0.0)\n"
     ]
    }
   ],
   "source": [
    "for z in result:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "_, predicted = torch.max(output, 0)\n",
    "value = predicted.data.tolist()\n",
    "value\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral',\n",
       " 'worry',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'love',\n",
       " 'surprise',\n",
       " 'fun',\n",
       " 'relief',\n",
       " 'hate',\n",
       " 'empty',\n",
       " 'enthusiasm',\n",
       " 'boredom',\n",
       " 'anger']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
