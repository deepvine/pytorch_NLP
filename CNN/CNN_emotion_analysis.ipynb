{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import vocab\n",
    "from torchtext import data\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator\n",
    "from torchtext.vocab import GloVe\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    return x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = \"<blank>\"\n",
    "max_vocab = 8000\n",
    "fix_length=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize=lambda x: x.split(), pad_token=BLANK_WORD, lower=True, batch_first=True, fix_length=fix_length)\n",
    "LABEL = Field(sequential=False, unk_token=None, tokenize=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(path='./text_emotion.csv', \n",
    "                            format='csv', \n",
    "                            skip_header=True,\n",
    "                            fields=[(\"tweet_id\", None),(\"sentiment\", LABEL),(\"author\", None),(\"content\",TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cbbd29dc0741049b26b3f129b8a738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove = vocab.Vectors('data/glove.6B.300d.txt')\n",
    "tqdm_notebook().pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vec = vocab.Vectors('glove.twitter.27B.100d.txt', './data/glove_embedding/')\n",
    "#https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.build_vocab(train_data, max_size=max_vocab)\n",
    "TEXT.build_vocab(train_data, min_freq=3)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.set_vectors(glove.stoi, glove.vectors, dim=300)\n",
    "TEXT.fix_length = fix_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@tiffanylue', 'i', 'know']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_example = train_data.examples[0]\n",
    "one_example.content[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_loader = Iterator(train_data, \n",
    "                        batch_size=64, \n",
    "                        device=-1, \n",
    "                        repeat=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    break;\n",
    "print(batch.content.shape)\n",
    "print(batch.sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/TEXT.Field\",\"wb\")as f:\n",
    "     dill.dump(TEXT,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/LABEL.Field\",\"wb\")as f2:\n",
    "     dill.dump(LABEL,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(model, method='xavier', exclude='embedding', seed=123):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    for name, w in model.named_parameters():\n",
    "        if not exclude in name:\n",
    "            if 'weight' in name:\n",
    "                if method is 'xavier':\n",
    "                    nn.init.xavier_normal_(w)\n",
    "                elif method is 'kaiming':\n",
    "                    nn.init.kaiming_normal_(w)\n",
    "                else:\n",
    "                    nn.init.normal_(w)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(w, 0.0)\n",
    "            else: \n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model, ignore='embedding'):\n",
    "    total = 0\n",
    "    for name, w in model.named_parameters():\n",
    "        if not ignore or ignore not in name:\n",
    "            total += w.nelement()\n",
    "            print('{} : {}  {} parameters'.format(name, w.shape, w.nelement()))\n",
    "    print('-------'*4)\n",
    "    print('Total {} parameters'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/TEXT.Field\",\"rb\")as f:\n",
    "     TEXT=dill.load(f)\n",
    "        \n",
    "with open(\"model/LABEL.Field\",\"rb\")as f2:\n",
    "     LABEL=dill.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "epochs=200\n",
    "embidding_dim = 300\n",
    "seq_length = 50\n",
    "vocab_size = len(TEXT.vocab.itos)\n",
    "num_filters = 128\n",
    "kernel_sizes = [3,4,5]\n",
    "hidden_dim = 128 # hidden size of fully conntected layer\n",
    "label_size = len(LABEL.vocab)\n",
    "print_every = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    #num_filters = out-channels\n",
    "    def __init__(self, lm, padding_idx, vocab_size, embedding_dim, num_filters, kernel_sizes, num_classes, dropout_prob):\n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding = nn.Embedding.from_pretrained(lm)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_sizes[0], embedding_dim))\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_sizes[1], embedding_dim))\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(kernel_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(kernel_sizes)*num_filters, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        #x = [batch size, sent len]\n",
    "        x = inputs\n",
    "\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = self.embedding(x)\n",
    "        #print(embedded.shape)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        #print(embedded.shape)\n",
    "        \n",
    "        #conv_n = [batch size, n_filters, sent_len - filter_sizes[n]]\n",
    "        conved1 = F.relu(self.conv1(embedded).squeeze(3))\n",
    "        conved2 = F.relu(self.conv2(embedded).squeeze(3))\n",
    "        conved3 = F.relu(self.conv3(embedded).squeeze(3))\n",
    "        #print(conved11.shape)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        pooled1 = F.max_pool1d(conved1, conved1.shape[2]).squeeze(2)\n",
    "        pooled2 = F.max_pool1d(conved2, conved2.shape[2]).squeeze(2)\n",
    "        pooled3 = F.max_pool1d(conved3, conved3.shape[2]).squeeze(2)\n",
    "        #print(pooled11.shape)\n",
    "        \n",
    "        \n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        cat = self.dropout(torch.cat((pooled1, pooled2, pooled3), dim=1))\n",
    "        #print(cat.shape)\n",
    "        \n",
    "        fc = self.fc(cat)\n",
    "        return fc\n",
    "        #return F.log_softmax(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용할 수 있는지 확인\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "#train_on_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (embedding): Embedding(11631, 300, padding_idx=1)\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 300), stride=(1, 1))\n",
       "  (conv2): Conv2d(1, 128, kernel_size=(4, 300), stride=(1, 1))\n",
       "  (conv3): Conv2d(1, 128, kernel_size=(5, 300), stride=(1, 1))\n",
       "  (fc): Linear(in_features=384, out_features=13, bias=True)\n",
       "  (dropout): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextCNN(TEXT.vocab.vectors, TEXT.vocab.stoi[TEXT.pad_token], vocab_size, embidding_dim, num_filters, kernel_sizes, label_size, 0.1)\n",
    "init_network(model)\n",
    "if(train_on_gpu):\n",
    "    model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight : torch.Size([11631, 300])  3489300 parameters\n",
      "conv1.weight : torch.Size([128, 1, 3, 300])  115200 parameters\n",
      "conv1.bias : torch.Size([128])  128 parameters\n",
      "conv2.weight : torch.Size([128, 1, 4, 300])  153600 parameters\n",
      "conv2.bias : torch.Size([128])  128 parameters\n",
      "conv3.weight : torch.Size([128, 1, 5, 300])  192000 parameters\n",
      "conv3.bias : torch.Size([128])  128 parameters\n",
      "fc.weight : torch.Size([13, 384])  4992 parameters\n",
      "fc.bias : torch.Size([13])  13 parameters\n",
      "----------------------------\n",
      "Total 3955489 parameters\n"
     ]
    }
   ],
   "source": [
    "criterion = F.cross_entropy\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,momentum=0.8)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "print_model(model, ignore=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200... Step: 1000... Loss: 2.0054...\n",
      "Epoch: 2/200... Step: 2000... Loss: 1.9270...\n",
      "Epoch: 3/200... Step: 3000... Loss: 1.7252...\n",
      "Epoch: 4/200... Step: 4000... Loss: 1.4458...\n",
      "Epoch: 4/200... Step: 5000... Loss: 1.5459...\n",
      "Epoch: 5/200... Step: 6000... Loss: 1.6439...\n",
      "Epoch: 6/200... Step: 7000... Loss: 1.2206...\n",
      "Epoch: 7/200... Step: 8000... Loss: 0.9150...\n",
      "Epoch: 8/200... Step: 9000... Loss: 0.7754...\n",
      "Epoch: 8/200... Step: 10000... Loss: 1.0881...\n",
      "Epoch: 9/200... Step: 11000... Loss: 0.9381...\n",
      "Epoch: 10/200... Step: 12000... Loss: 0.9848...\n",
      "Epoch: 11/200... Step: 13000... Loss: 0.6031...\n",
      "Epoch: 12/200... Step: 14000... Loss: 0.7047...\n",
      "Epoch: 12/200... Step: 15000... Loss: 0.6862...\n",
      "Epoch: 13/200... Step: 16000... Loss: 0.7743...\n",
      "Epoch: 14/200... Step: 17000... Loss: 0.5336...\n",
      "Epoch: 15/200... Step: 18000... Loss: 0.6734...\n",
      "Epoch: 16/200... Step: 19000... Loss: 0.5369...\n",
      "Epoch: 16/200... Step: 20000... Loss: 0.5121...\n",
      "Epoch: 17/200... Step: 21000... Loss: 0.6138...\n",
      "Epoch: 18/200... Step: 22000... Loss: 0.6949...\n",
      "Epoch: 19/200... Step: 23000... Loss: 0.4147...\n",
      "Epoch: 20/200... Step: 24000... Loss: 0.4819...\n",
      "Epoch: 20/200... Step: 25000... Loss: 0.3996...\n",
      "Epoch: 21/200... Step: 26000... Loss: 0.4829...\n",
      "Epoch: 22/200... Step: 27000... Loss: 0.3472...\n",
      "Epoch: 23/200... Step: 28000... Loss: 0.3134...\n",
      "Epoch: 24/200... Step: 29000... Loss: 0.4510...\n",
      "Epoch: 24/200... Step: 30000... Loss: 0.4779...\n",
      "Epoch: 25/200... Step: 31000... Loss: 0.5417...\n",
      "Epoch: 26/200... Step: 32000... Loss: 0.2791...\n",
      "Epoch: 27/200... Step: 33000... Loss: 0.2826...\n",
      "Epoch: 28/200... Step: 34000... Loss: 0.3026...\n",
      "Epoch: 28/200... Step: 35000... Loss: 0.4716...\n",
      "Epoch: 29/200... Step: 36000... Loss: 0.4977...\n",
      "Epoch: 30/200... Step: 37000... Loss: 0.3416...\n",
      "Epoch: 31/200... Step: 38000... Loss: 0.2590...\n",
      "Epoch: 32/200... Step: 39000... Loss: 0.2774...\n",
      "Epoch: 32/200... Step: 40000... Loss: 0.3554...\n",
      "Epoch: 33/200... Step: 41000... Loss: 0.2627...\n",
      "Epoch: 34/200... Step: 42000... Loss: 0.8070...\n",
      "Epoch: 35/200... Step: 43000... Loss: 0.2247...\n",
      "Epoch: 36/200... Step: 44000... Loss: 0.2593...\n",
      "Epoch: 36/200... Step: 45000... Loss: 0.2539...\n",
      "Epoch: 37/200... Step: 46000... Loss: 0.2294...\n",
      "Epoch: 38/200... Step: 47000... Loss: 0.4005...\n",
      "Epoch: 39/200... Step: 48000... Loss: 0.2201...\n",
      "Epoch: 40/200... Step: 49000... Loss: 0.2433...\n",
      "Epoch: 40/200... Step: 50000... Loss: 0.3677...\n",
      "Epoch: 41/200... Step: 51000... Loss: 0.3589...\n",
      "Epoch: 42/200... Step: 52000... Loss: 0.2947...\n",
      "Epoch: 43/200... Step: 53000... Loss: 0.3961...\n",
      "Epoch: 44/200... Step: 54000... Loss: 0.4098...\n",
      "Epoch: 44/200... Step: 55000... Loss: 0.2991...\n",
      "Epoch: 45/200... Step: 56000... Loss: 0.6400...\n",
      "Epoch: 46/200... Step: 57000... Loss: 0.3200...\n",
      "Epoch: 47/200... Step: 58000... Loss: 0.1635...\n",
      "Epoch: 48/200... Step: 59000... Loss: 0.1917...\n",
      "Epoch: 48/200... Step: 60000... Loss: 0.2393...\n",
      "Epoch: 49/200... Step: 61000... Loss: 0.1706...\n",
      "Epoch: 50/200... Step: 62000... Loss: 0.1856...\n",
      "Epoch: 51/200... Step: 63000... Loss: 0.2795...\n",
      "Epoch: 52/200... Step: 64000... Loss: 0.5217...\n",
      "Epoch: 52/200... Step: 65000... Loss: 0.4542...\n",
      "Epoch: 53/200... Step: 66000... Loss: 0.2675...\n",
      "Epoch: 54/200... Step: 67000... Loss: 0.1421...\n",
      "Epoch: 55/200... Step: 68000... Loss: 0.1952...\n",
      "Epoch: 56/200... Step: 69000... Loss: 0.7312...\n",
      "Epoch: 56/200... Step: 70000... Loss: 0.2779...\n",
      "Epoch: 57/200... Step: 71000... Loss: 0.2012...\n",
      "Epoch: 58/200... Step: 72000... Loss: 0.2814...\n",
      "Epoch: 59/200... Step: 73000... Loss: 0.1180...\n",
      "Epoch: 60/200... Step: 74000... Loss: 0.0975...\n",
      "Epoch: 60/200... Step: 75000... Loss: 0.2810...\n",
      "Epoch: 61/200... Step: 76000... Loss: 0.3709...\n",
      "Epoch: 62/200... Step: 77000... Loss: 0.3582...\n",
      "Epoch: 63/200... Step: 78000... Loss: 0.0842...\n",
      "Epoch: 64/200... Step: 79000... Loss: 0.1511...\n",
      "Epoch: 64/200... Step: 80000... Loss: 0.3963...\n",
      "Epoch: 65/200... Step: 81000... Loss: 0.2227...\n",
      "Epoch: 66/200... Step: 82000... Loss: 0.1779...\n",
      "Epoch: 67/200... Step: 83000... Loss: 0.1258...\n",
      "Epoch: 68/200... Step: 84000... Loss: 0.1120...\n",
      "Epoch: 68/200... Step: 85000... Loss: 0.1699...\n",
      "Epoch: 69/200... Step: 86000... Loss: 0.2238...\n",
      "Epoch: 70/200... Step: 87000... Loss: 0.2120...\n",
      "Epoch: 71/200... Step: 88000... Loss: 0.1724...\n",
      "Epoch: 72/200... Step: 89000... Loss: 0.4066...\n",
      "Epoch: 72/200... Step: 90000... Loss: 0.1835...\n",
      "Epoch: 73/200... Step: 91000... Loss: 0.2451...\n",
      "Epoch: 74/200... Step: 92000... Loss: 0.2074...\n",
      "Epoch: 75/200... Step: 93000... Loss: 0.1739...\n",
      "Epoch: 76/200... Step: 94000... Loss: 0.1266...\n",
      "Epoch: 76/200... Step: 95000... Loss: 0.1124...\n",
      "Epoch: 77/200... Step: 96000... Loss: 0.1670...\n",
      "Epoch: 78/200... Step: 97000... Loss: 0.1173...\n",
      "Epoch: 79/200... Step: 98000... Loss: 0.2440...\n",
      "Epoch: 80/200... Step: 99000... Loss: 0.1666...\n",
      "Epoch: 80/200... Step: 100000... Loss: 0.1928...\n",
      "Epoch: 81/200... Step: 101000... Loss: 0.3894...\n",
      "Epoch: 82/200... Step: 102000... Loss: 0.5295...\n",
      "Epoch: 83/200... Step: 103000... Loss: 0.0775...\n",
      "Epoch: 84/200... Step: 104000... Loss: 0.2682...\n",
      "Epoch: 84/200... Step: 105000... Loss: 0.2925...\n",
      "Epoch: 85/200... Step: 106000... Loss: 0.1726...\n",
      "Epoch: 86/200... Step: 107000... Loss: 0.1658...\n",
      "Epoch: 87/200... Step: 108000... Loss: 0.1750...\n",
      "Epoch: 88/200... Step: 109000... Loss: 0.1054...\n",
      "Epoch: 88/200... Step: 110000... Loss: 0.2025...\n",
      "Epoch: 89/200... Step: 111000... Loss: 0.1665...\n",
      "Epoch: 90/200... Step: 112000... Loss: 0.0779...\n",
      "Epoch: 91/200... Step: 113000... Loss: 0.1989...\n",
      "Epoch: 92/200... Step: 114000... Loss: 0.1980...\n",
      "Epoch: 92/200... Step: 115000... Loss: 0.1347...\n",
      "Epoch: 93/200... Step: 116000... Loss: 0.1858...\n",
      "Epoch: 94/200... Step: 117000... Loss: 0.2609...\n",
      "Epoch: 95/200... Step: 118000... Loss: 0.2187...\n",
      "Epoch: 96/200... Step: 119000... Loss: 0.5582...\n",
      "Epoch: 96/200... Step: 120000... Loss: 0.0699...\n",
      "Epoch: 97/200... Step: 121000... Loss: 0.0759...\n",
      "Epoch: 98/200... Step: 122000... Loss: 0.3219...\n",
      "Epoch: 99/200... Step: 123000... Loss: 0.1927...\n",
      "Epoch: 100/200... Step: 124000... Loss: 0.0626...\n",
      "Epoch: 100/200... Step: 125000... Loss: 0.0932...\n",
      "Epoch: 101/200... Step: 126000... Loss: 0.0945...\n",
      "Epoch: 102/200... Step: 127000... Loss: 0.1557...\n",
      "Epoch: 103/200... Step: 128000... Loss: 0.4347...\n",
      "Epoch: 104/200... Step: 129000... Loss: 0.0816...\n",
      "Epoch: 104/200... Step: 130000... Loss: 0.2322...\n",
      "Epoch: 105/200... Step: 131000... Loss: 0.1400...\n",
      "Epoch: 106/200... Step: 132000... Loss: 0.1558...\n",
      "Epoch: 107/200... Step: 133000... Loss: 0.1548...\n",
      "Epoch: 108/200... Step: 134000... Loss: 0.0971...\n",
      "Epoch: 108/200... Step: 135000... Loss: 0.2902...\n",
      "Epoch: 109/200... Step: 136000... Loss: 0.1453...\n",
      "Epoch: 110/200... Step: 137000... Loss: 0.1275...\n",
      "Epoch: 111/200... Step: 138000... Loss: 0.1508...\n",
      "Epoch: 112/200... Step: 139000... Loss: 0.2354...\n",
      "Epoch: 112/200... Step: 140000... Loss: 0.0985...\n",
      "Epoch: 113/200... Step: 141000... Loss: 0.0733...\n",
      "Epoch: 114/200... Step: 142000... Loss: 0.0567...\n",
      "Epoch: 115/200... Step: 143000... Loss: 0.1623...\n",
      "Epoch: 116/200... Step: 144000... Loss: 0.3195...\n",
      "Epoch: 116/200... Step: 145000... Loss: 0.1895...\n",
      "Epoch: 117/200... Step: 146000... Loss: 0.1830...\n",
      "Epoch: 118/200... Step: 147000... Loss: 0.0685...\n",
      "Epoch: 119/200... Step: 148000... Loss: 0.2345...\n",
      "Epoch: 120/200... Step: 149000... Loss: 0.0506...\n",
      "Epoch: 120/200... Step: 150000... Loss: 0.2156...\n",
      "Epoch: 121/200... Step: 151000... Loss: 0.2143...\n",
      "Epoch: 122/200... Step: 152000... Loss: 0.4653...\n",
      "Epoch: 123/200... Step: 153000... Loss: 0.1708...\n",
      "Epoch: 124/200... Step: 154000... Loss: 0.1634...\n",
      "Epoch: 124/200... Step: 155000... Loss: 0.2942...\n",
      "Epoch: 125/200... Step: 156000... Loss: 0.4493...\n",
      "Epoch: 126/200... Step: 157000... Loss: 0.3547...\n",
      "Epoch: 127/200... Step: 158000... Loss: 0.2068...\n",
      "Epoch: 128/200... Step: 159000... Loss: 0.2157...\n",
      "Epoch: 128/200... Step: 160000... Loss: 0.0309...\n",
      "Epoch: 129/200... Step: 161000... Loss: 0.1068...\n",
      "Epoch: 130/200... Step: 162000... Loss: 0.1438...\n",
      "Epoch: 131/200... Step: 163000... Loss: 0.1571...\n",
      "Epoch: 132/200... Step: 164000... Loss: 0.0767...\n",
      "Epoch: 132/200... Step: 165000... Loss: 0.4116...\n",
      "Epoch: 133/200... Step: 166000... Loss: 0.2269...\n",
      "Epoch: 134/200... Step: 167000... Loss: 0.1702...\n",
      "Epoch: 135/200... Step: 168000... Loss: 0.2152...\n",
      "Epoch: 136/200... Step: 169000... Loss: 0.0745...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/200... Step: 170000... Loss: 0.6293...\n",
      "Epoch: 137/200... Step: 171000... Loss: 0.2843...\n",
      "Epoch: 138/200... Step: 172000... Loss: 0.0619...\n",
      "Epoch: 139/200... Step: 173000... Loss: 0.0563...\n",
      "Epoch: 140/200... Step: 174000... Loss: 0.3814...\n",
      "Epoch: 140/200... Step: 175000... Loss: 0.3445...\n",
      "Epoch: 141/200... Step: 176000... Loss: 0.1387...\n",
      "Epoch: 142/200... Step: 177000... Loss: 0.2497...\n",
      "Epoch: 143/200... Step: 178000... Loss: 0.1744...\n",
      "Epoch: 144/200... Step: 179000... Loss: 0.1871...\n",
      "Epoch: 144/200... Step: 180000... Loss: 0.3278...\n",
      "Epoch: 145/200... Step: 181000... Loss: 0.2158...\n",
      "Epoch: 146/200... Step: 182000... Loss: 0.2493...\n",
      "Epoch: 147/200... Step: 183000... Loss: 0.1050...\n",
      "Epoch: 148/200... Step: 184000... Loss: 0.2431...\n",
      "Epoch: 148/200... Step: 185000... Loss: 0.1136...\n",
      "Epoch: 149/200... Step: 186000... Loss: 0.1674...\n",
      "Epoch: 150/200... Step: 187000... Loss: 0.2166...\n",
      "Epoch: 151/200... Step: 188000... Loss: 0.2013...\n",
      "Epoch: 152/200... Step: 189000... Loss: 0.0428...\n",
      "Epoch: 152/200... Step: 190000... Loss: 0.3607...\n",
      "Epoch: 153/200... Step: 191000... Loss: 0.2692...\n",
      "Epoch: 154/200... Step: 192000... Loss: 0.0833...\n",
      "Epoch: 155/200... Step: 193000... Loss: 0.2035...\n",
      "Epoch: 156/200... Step: 194000... Loss: 0.1163...\n",
      "Epoch: 156/200... Step: 195000... Loss: 0.2461...\n",
      "Epoch: 157/200... Step: 196000... Loss: 0.1058...\n",
      "Epoch: 158/200... Step: 197000... Loss: 0.1334...\n",
      "Epoch: 159/200... Step: 198000... Loss: 0.2279...\n",
      "Epoch: 160/200... Step: 199000... Loss: 0.3470...\n",
      "Epoch: 160/200... Step: 200000... Loss: 0.2580...\n",
      "Epoch: 161/200... Step: 201000... Loss: 0.1457...\n",
      "Epoch: 162/200... Step: 202000... Loss: 0.1079...\n",
      "Epoch: 163/200... Step: 203000... Loss: 0.1820...\n",
      "Epoch: 164/200... Step: 204000... Loss: 0.3426...\n",
      "Epoch: 164/200... Step: 205000... Loss: 0.1216...\n",
      "Epoch: 165/200... Step: 206000... Loss: 0.2088...\n",
      "Epoch: 166/200... Step: 207000... Loss: 0.1373...\n",
      "Epoch: 167/200... Step: 208000... Loss: 0.6653...\n",
      "Epoch: 168/200... Step: 209000... Loss: 0.1096...\n",
      "Epoch: 168/200... Step: 210000... Loss: 0.1459...\n",
      "Epoch: 169/200... Step: 211000... Loss: 0.1291...\n",
      "Epoch: 170/200... Step: 212000... Loss: 0.2679...\n",
      "Epoch: 171/200... Step: 213000... Loss: 0.3028...\n",
      "Epoch: 172/200... Step: 214000... Loss: 0.1092...\n",
      "Epoch: 172/200... Step: 215000... Loss: 0.0882...\n",
      "Epoch: 173/200... Step: 216000... Loss: 0.1674...\n",
      "Epoch: 174/200... Step: 217000... Loss: 0.2761...\n",
      "Epoch: 175/200... Step: 218000... Loss: 0.1146...\n",
      "Epoch: 176/200... Step: 219000... Loss: 0.0433...\n",
      "Epoch: 176/200... Step: 220000... Loss: 0.1399...\n",
      "Epoch: 177/200... Step: 221000... Loss: 0.0759...\n",
      "Epoch: 178/200... Step: 222000... Loss: 0.1761...\n",
      "Epoch: 179/200... Step: 223000... Loss: 0.1444...\n",
      "Epoch: 180/200... Step: 224000... Loss: 0.1168...\n",
      "Epoch: 180/200... Step: 225000... Loss: 0.3281...\n",
      "Epoch: 181/200... Step: 226000... Loss: 0.2193...\n",
      "Epoch: 182/200... Step: 227000... Loss: 0.2156...\n",
      "Epoch: 183/200... Step: 228000... Loss: 0.0769...\n",
      "Epoch: 184/200... Step: 229000... Loss: 0.1825...\n",
      "Epoch: 184/200... Step: 230000... Loss: 0.1371...\n",
      "Epoch: 185/200... Step: 231000... Loss: 0.1181...\n",
      "Epoch: 186/200... Step: 232000... Loss: 0.0389...\n",
      "Epoch: 187/200... Step: 233000... Loss: 0.0727...\n",
      "Epoch: 188/200... Step: 234000... Loss: 0.2106...\n",
      "Epoch: 188/200... Step: 235000... Loss: 0.1106...\n",
      "Epoch: 189/200... Step: 236000... Loss: 0.1520...\n",
      "Epoch: 190/200... Step: 237000... Loss: 0.2015...\n",
      "Epoch: 191/200... Step: 238000... Loss: 0.0518...\n",
      "Epoch: 192/200... Step: 239000... Loss: 0.0469...\n",
      "Epoch: 192/200... Step: 240000... Loss: 0.3474...\n",
      "Epoch: 193/200... Step: 241000... Loss: 0.1622...\n",
      "Epoch: 194/200... Step: 242000... Loss: 0.0608...\n",
      "Epoch: 195/200... Step: 243000... Loss: 0.0851...\n",
      "Epoch: 196/200... Step: 244000... Loss: 0.0922...\n",
      "Epoch: 196/200... Step: 245000... Loss: 0.0634...\n",
      "Epoch: 197/200... Step: 246000... Loss: 0.1277...\n",
      "Epoch: 198/200... Step: 247000... Loss: 0.3268...\n",
      "Epoch: 199/200... Step: 248000... Loss: 0.1046...\n",
      "Epoch: 200/200... Step: 249000... Loss: 0.2035...\n",
      "Epoch: 200/200... Step: 250000... Loss: 0.2511...\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "counter = 0\n",
    "index = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        counter += 1\n",
    "        \n",
    "        #if len(batch) != batch_size: continue\n",
    "        if(train_on_gpu):\n",
    "            inputs, targets = Variable(batch.content).cuda(), Variable(batch.sentiment).cuda()\n",
    "        else:\n",
    "            inputs, targets = batch.content, batch.sentiment\n",
    "        counter += 1\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(inputs)\n",
    "        #print(\"output: \", output.shape)\n",
    "        #print(\"targets: \", targets.shape)\n",
    "        \n",
    "        #loss = criterion(output, targets)\n",
    "        loss = F.cross_entropy(output, targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % print_every == 0:\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename = \"document_cls_text_cnn10.pth\"\n",
    "PATH = os.path.join(\"model\", filename)\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TextCNN(TEXT.vocab.vectors, TEXT.vocab.stoi[TEXT.pad_token], num_filters, kernel_sizes, label_size, 0.5)\n",
    "model = TextCNN(TEXT.vocab.vectors, TEXT.vocab.stoi[TEXT.pad_token], vocab_size, embidding_dim, num_filters, kernel_sizes, label_size, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = \"How are YOU convinced that I have always wanted you? What signals did I give off...damn I think I just lost another friend\"\n",
    "#sentence = \"The storm is here and the electricity is gone\"\n",
    "#sentence = \"Damm servers still down  i need to hit 80 before all the koxpers pass me\"\n",
    "#sentence = \"Need to pack for CALI CALI! Cannot waittt! Thinking a glass of wine is in order to celebrate my weekend vaca. Still work 2morrow, tho.\"\n",
    "#sentence = \"I'm worried I can do anything\"\n",
    "##sentence = \"I felt ecstatic when I passed my exam\"\n",
    "#sentence = \"I was overjoyed at the birth of my son.\"\n",
    "sentence = \"During the Christmas holidays I felt wonderfully merry.\"\n",
    "#sentence = \"I’m feeling a little low at the moment.\"\n",
    "#sentence = \"I was so annoyed when I failed my English test.\"\n",
    "#sentence = \"Afraid of your own shadow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[828, 4, 3278, 1925, 2, 872, 0, 0]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [TEXT.vocab.stoi[word.lower()] for word in tokenizer(sentence)]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse = np.asarray(s)\n",
    "feature_tensor = torch.from_numpy(nse)\n",
    "feature_tensor = feature_tensor.unsqueeze(0)\n",
    "batch_size = feature_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "if(train_on_gpu):\n",
    "    feature_tensor = feature_tensor.cuda()\n",
    "    model.cuda()\n",
    "\n",
    "model.eval()\n",
    "print(feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3.4776,   3.9867,  -1.0742,   1.3718,   2.4690,  -5.4473,  -7.9056,\n",
       "        -15.8092, -10.7468,  -4.9786,  -8.9972, -10.3861, -16.7447],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(feature_tensor).squeeze()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3.4776,   3.9867,  -1.0742,   1.3718,   2.4690,  -5.4473,  -7.9056,\n",
       "        -15.8092, -10.7468,  -4.9786,  -8.9972, -10.3861, -16.7447],\n",
       "       grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pred = F.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "val,idx = pred.sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2631e-01, 3.1634e-01, 1.1538e-01, 3.8514e-02, 3.3369e-03, 6.7245e-05,\n",
       "        4.2082e-05, 3.6016e-06, 1.2089e-06, 3.0147e-07, 2.1017e-07, 1.3304e-09,\n",
       "        5.2203e-10], device='cuda:0', grad_fn=<SortBackward>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0,  4,  3,  2,  9,  5,  6, 10, 11,  8,  7, 12], device='cuda:0')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263\n",
      "0.3163\n",
      "0.1154\n",
      "0.0385\n",
      "0.0033\n",
      "0.0001\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "value = []\n",
    "for v in val.tolist():\n",
    "    v = round(v, 4)\n",
    "    value.append(v)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5263, 0.3163, 0.1154, 0.0385]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "9\n",
      "5\n",
      "6\n",
      "10\n",
      "11\n",
      "8\n",
      "7\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "emotion = []\n",
    "for v in idx.tolist():\n",
    "    emotion.append(LABEL.vocab.itos[v])\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worry', 'neutral', 'love', 'sadness']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fc776133d08>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = zip(emotion, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('worry', 0.5263)\n",
      "('neutral', 0.3163)\n",
      "('love', 0.1154)\n",
      "('sadness', 0.0385)\n",
      "('happiness', 0.0033)\n",
      "('empty', 0.0001)\n",
      "('surprise', 0.0)\n",
      "('fun', 0.0)\n",
      "('enthusiasm', 0.0)\n",
      "('boredom', 0.0)\n",
      "('hate', 0.0)\n",
      "('relief', 0.0)\n",
      "('anger', 0.0)\n"
     ]
    }
   ],
   "source": [
    "for z in result:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "_, predicted = torch.max(output, 0)\n",
    "value = predicted.data.tolist()\n",
    "value\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral',\n",
       " 'worry',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'love',\n",
       " 'surprise',\n",
       " 'fun',\n",
       " 'relief',\n",
       " 'hate',\n",
       " 'empty',\n",
       " 'enthusiasm',\n",
       " 'boredom',\n",
       " 'anger']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
